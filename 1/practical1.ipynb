{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First pratical of the Unsupervised Language Learning course 2017-2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joris Mollinga: 11871431 \n",
    "\n",
    "Aron Hammond: 10437215"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sklearn\n",
    "import pprint\n",
    "from collections import deque\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the word embeddings file\n",
    "def readWORDSfile(fileName):\n",
    "    word2vec = {}\n",
    "\n",
    "    with open (fileName,'r',encoding=\"utf8\") as emb:\n",
    "        for line in emb:\n",
    "            row = line.split()\n",
    "            word = row[0]\n",
    "            embedding = row[1:]\n",
    "\n",
    "            # Convert to floats and assign in dictionary\n",
    "            word2vec[word] = [float(i) for i in embedding] \n",
    "    return word2vec\n",
    "\n",
    "def read2000words(fileName):\n",
    "        \n",
    "    with open (fileName,'r') as nouns:\n",
    "        words = nouns.readlines()\n",
    "        \n",
    "    words = [i.split()[0] for i in words]\n",
    "            \n",
    "    return words\n",
    "\n",
    "def readMEN(fileName):\n",
    "    judgements = []\n",
    "    \n",
    "    with open (fileName,'r') as file:\n",
    "        for line in file:\n",
    "            judgements.append(line.split())\n",
    "    \n",
    "    return judgements\n",
    "\n",
    "def readSimLex(fileName):\n",
    "    judgements = []\n",
    "    \n",
    "    with open (fileName,'r') as file:\n",
    "        for i, line in enumerate(file):\n",
    "            if i == 0: continue\n",
    "            judgement = line.split('\\t')\n",
    "            judgements.append([judgement[0], judgement[1], judgement[3]])\n",
    "            \n",
    "    return judgements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = readWORDSfile('deps.WORDS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow2 = readWORDSfile('bow2.WORDS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow5 = readWORDSfile('bow5.WORDS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = read2000words('2000_nouns_sorted.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "men = readMEN(os.path.join('MEN', 'MEN_dataset_natural_form_full'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simlex = readSimLex(os.path.join('SimLex-999', 'SimLex-999.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(word1, word2, model):\n",
    "    '''Compute the cosine similarity of the embeddings of word1 and word2 under the supplied model'''\n",
    "    \n",
    "    if not word1 in model or not word2 in model:\n",
    "        return 0\n",
    "    \n",
    "    emb1 = model[word1]\n",
    "    emb2 = model[word2]\n",
    "    \n",
    "    unit_emb1 = emb1 / np.linalg.norm(emb1)\n",
    "    unit_emb2 = emb2 / np.linalg.norm(emb2)\n",
    "    \n",
    "    return np.dot(unit_emb1, unit_emb2)\n",
    "\n",
    "def evaluate_models_on_set(judgements):\n",
    "    result = []\n",
    "    used = []\n",
    "    \n",
    "    for pair in judgements:\n",
    "        word1, word2, score = pair\n",
    "        bow2sim = similarity(word1, word2, bow2)\n",
    "        bow5sim = similarity(word1, word2, bow5)\n",
    "        depssim = similarity(word1, word2, word2vec)\n",
    "        \n",
    "        row = [bow2sim, bow5sim, depssim]\n",
    "        \n",
    "        if not all(row):\n",
    "            continue\n",
    "        \n",
    "        result.append(row)\n",
    "        used.append(pair)\n",
    "    \n",
    "    return np.array(result, dtype=np.float64), used\n",
    "\n",
    "def pearson(results, scores):\n",
    "    corr = []\n",
    "    for i in range(np.size(results, 1)):\n",
    "        corr.append(pearsonr(results[:,i], scores)[0])\n",
    "        \n",
    "    return np.array(corr)\n",
    "\n",
    "def top5_similar(model, word):\n",
    "    top5 = deque()\n",
    "    \n",
    "    if word in model:\n",
    "        emb = model[word]\n",
    "    \n",
    "    \n",
    "\n",
    "# Compute cosine similarity between the words using the three models\n",
    "# words that don't occur in the models are skipped and removed from\n",
    "# the evaluation set.\n",
    "MENResults, men = evaluate_models_on_set(men)\n",
    "SimLexResults, simlex = evaluate_models_on_set(simlex)\n",
    "    \n",
    "# Evaluate the model-produced similarities against human judgements in terms of \n",
    "# Pearson and Spearman correlation coefficients.\n",
    "\n",
    "# Collect human judgements (last column of dataset)\n",
    "MENScores = np.array([judgement[-1] for judgement in men], dtype=np.float64)\n",
    "SimLexScores = np.array([judgement[-1] for judgement in simlex], dtype=np.float64)\n",
    "\n",
    "correlations = {\"MEN\" : {\n",
    "                   \"Spearman\" : [],\n",
    "                   \"Pearson\" : []},\n",
    "               \"SimLex\" : {\n",
    "                   \"Spearman\" : [],\n",
    "                   \"Pearson\" : []\n",
    "               }}\n",
    "\n",
    "correlations[\"MEN\"][\"Spearman\"] = spearmanr(MENResults, MENScores, axis = 0).correlation[0:3,-1]\n",
    "correlations[\"MEN\"][\"Pearson\"] = pearson(MENResults, MENScores)\n",
    "correlations[\"SimLex\"][\"Spearman\"] = spearmanr(SimLexResults, SimLexScores, axis = 0).correlation[0:3,-1]\n",
    "correlations[\"SimLex\"][\"Pearson\"] = pearson(SimLexResults, SimLexScores)\n",
    "\n",
    "pprint.pprint(correlations)\n",
    "\n",
    "# Compare the performance of the three models on this task.\n",
    "\n",
    "#  Analyze the data qualitatively and report what are the differences in the kind\n",
    "# of similarity captured by the three models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at both Pearson and Spearman correlations, the similarity scores for \\texttt{bow5} seem to correlate the best with the MEN evaluations but worst with SimLex. This is most likeley due to the fact that SimLex focusses on similarity rather than relatedness and a larger window captures relatively more topical relations. As expected, the dependency based embeddings have the highest correlation on SimLex.\n",
    "What is curious, is that correlations with MEN are striclty larger than those on SimLex. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Analogy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
